import sys
import subprocess
from pathlib import Path
import pandas as pd
import logging

# Configuration du logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def run_extract_db():
    """ExÃ©cute le script extract_db.py pour extraire les donnÃ©es de la base."""
    try:
        logger.info("DÃ©but de l'extraction depuis la base de donnÃ©es...")
        
        # Import direct pour rÃ©cupÃ©rer le DataFrame
        from Extract.extract_db import extract_data_to_dataframe
        
        df = extract_data_to_dataframe()
        
        if df.empty:
            logger.warning("Aucune donnÃ©e extraite de la base de donnÃ©es")
            return None
        
        logger.info(f"âœ… Extraction DB terminÃ©e. {len(df)} lignes extraites.")
        return df
        
    except Exception as e:
        logger.error(f"âŒ Erreur lors de l'exÃ©cution de extract_db.py: {e}")
        return None

def run_cleaning(df: pd.DataFrame) -> pd.DataFrame:
    """ExÃ©cute le nettoyage des donnÃ©es."""
    try:
        logger.info("DÃ©but du nettoyage des donnÃ©es...")
        
        from Transform.data_cleaning import clean_data_from_db
        
        df_clean = clean_data_from_db()
        
        if df_clean.empty:
            logger.warning("Aucune donnÃ©e aprÃ¨s nettoyage")
            return df  # Retourne les donnÃ©es originales si Ã©chec
        
        logger.info(f"âœ… Nettoyage terminÃ©. {len(df_clean)} lignes traitÃ©es.")
        return df_clean
        
    except Exception as e:
        logger.error(f"âŒ Erreur lors du nettoyage: {e}")
        return df  # Retourne les donnÃ©es originales en cas d'erreur

def run_normalization(df: pd.DataFrame) -> pd.DataFrame:
    """ExÃ©cute la normalisation des dates."""
    try:
        logger.info("DÃ©but de la normalisation des dates...")
        
        from Transform.date_normalization import normalize_dates_from_db
        
        df_normalized = normalize_dates_from_db()
        
        if df_normalized.empty:
            logger.warning("Aucune donnÃ©e aprÃ¨s normalisation")
            return df
        
        logger.info(f"âœ… Normalisation des dates terminÃ©e.")
        return df_normalized
        
    except Exception as e:
        logger.error(f"âŒ Erreur lors de la normalisation: {e}")
        return df

def run_unit_conversion(df: pd.DataFrame) -> pd.DataFrame:
    """ExÃ©cute la conversion des unitÃ©s."""
    try:
        logger.info("DÃ©but de la conversion des unitÃ©s...")
        
        from Transform.unit_conversion import convert_units_from_db
        
        df_converted = convert_units_from_db()
        
        if df_converted.empty:
            logger.warning("Aucune donnÃ©e aprÃ¨s conversion")
            return df
        
        logger.info(f"âœ… Conversion des unitÃ©s terminÃ©e.")
        return df_converted
        
    except Exception as e:
        logger.error(f"âŒ Erreur lors de la conversion: {e}")
        return df

def save_final_data(df: pd.DataFrame, filename: str = "data_final.csv"):
    """Sauvegarde les donnÃ©es finales."""
    try:
        output_dir = Path(__file__).parent / "energitic_pipeline"
        output_dir.mkdir(exist_ok=True)
        
        output_path = output_dir / filename
        df.to_csv(output_path, index=False)
        
        logger.info(f"ğŸ’¾ DonnÃ©es sauvegardÃ©es dans: {output_path}")
        return output_path
        
    except Exception as e:
        logger.error(f"âŒ Erreur lors de la sauvegarde: {e}")
        return None

def run_transform_pipeline(df: pd.DataFrame) -> pd.DataFrame:
    """ExÃ©cute toute la logique de transformation dans l'ordre correct."""
    logger.info("ğŸš€ DÃ©marrage du pipeline de transformation...")
    
    # Ordre correct du pipeline :
    # 1. Cleaning des donnÃ©es
    df = run_cleaning(df)
    
    # 2. Normalisation des dates
    df = run_normalization(df)
    
    # 3. Conversion des unitÃ©s
    df = run_unit_conversion(df)
    
    logger.info("âœ¨ Pipeline Transform terminÃ© avec succÃ¨s!")
    return df

def display_pipeline_summary(df: pd.DataFrame):
    """Affiche un rÃ©sumÃ© du pipeline."""
    print("\n" + "="*50)
    print("ğŸ“Š RÃ‰SUMÃ‰ DU PIPELINE")
    print("="*50)
    print(f"ğŸ“ˆ Nombre total d'enregistrements: {len(df)}")
    print(f"ğŸ·ï¸  Nombre de colonnes: {len(df.columns)}")
    print(f"ğŸ“‹ Colonnes disponibles: {list(df.columns)}")
    
    # Afficher les statistiques de base
    if not df.empty:
        print(f"\nğŸ“Š AperÃ§u des donnÃ©es:")
        print(df.head())
        
        # Informations sur les valeurs manquantes
        missing_values = df.isnull().sum()
        if missing_values.sum() > 0:
            print(f"\nâš ï¸  Valeurs manquantes par colonne:")
            for col, count in missing_values[missing_values > 0].items():
                print(f"   - {col}: {count} valeurs manquantes")
        else:
            print(f"\nâœ… Aucune valeur manquante dÃ©tectÃ©e")

def main():
    """ExÃ©cute le pipeline complet selon la logique dÃ©finie."""
    logger.info("ğŸ¯ DÃ©marrage du pipeline complet...")
    
    # Ã‰tape 1: Extraction depuis la base de donnÃ©es
    df = run_extract_db()
    
    if df is None or df.empty:
        logger.error("âŒ Ã‰chec de l'extraction des donnÃ©es. ArrÃªt du pipeline.")
        return
    
    print(f"\nğŸ“¥ DonnÃ©es initiales extraites: {len(df)} lignes, {len(df.columns)} colonnes")
    
    # Ã‰tape 2: Pipeline de transformation
    df_final = run_transform_pipeline(df)
    
    if df_final is None or df_final.empty:
        logger.error("âŒ Ã‰chec du pipeline de transformation.")
        return
    
    # Ã‰tape 3: Sauvegarde des donnÃ©es finales
    saved_path = save_final_data(df_final)
    
    if saved_path:
        print(f"\nğŸ’¾ Fichier sauvegardÃ©: {saved_path}")
    
    # Ã‰tape 4: Affichage du rÃ©sumÃ©
    display_pipeline_summary(df_final)
    
    logger.info("ğŸ‰ Pipeline terminÃ© avec succÃ¨s!")

if __name__ == "__main__":
    main()